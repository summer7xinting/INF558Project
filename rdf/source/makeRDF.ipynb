{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files: companyRDF.csv, wikidata2.csv, cleaned_jobs.csv\n",
    "# output file: companyJobsRDF.ttl\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"companyRDF.csv\")\n",
    "df.fillna(\"missing!\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, XSD, Namespace\n",
    "from rdflib.namespace import RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.ldf.fi/service/rdf-grapher\n",
    "\n",
    "MYNS = Namespace('uri:xinting_myunghee:')\n",
    "schema = Namespace('http://schema.org/')\n",
    "my_kg = Graph()\n",
    "my_kg.bind('my_ns', MYNS)\n",
    "my_kg.bind('rdf', RDF)\n",
    "my_kg.bind('schema', schema)\n",
    "my_kg.bind('xsd', XSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidf = pd.read_csv(\"wikidata2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = {\"-1\"}\n",
    "remove2 = {(\"-1\", \"-1\")}\n",
    "def getwiki(idxes):\n",
    "    founder = set()\n",
    "    parentOrganization = set()\n",
    "    subOrganization = set()\n",
    "    CEO = set()\n",
    "\n",
    "    for idx in idxes:\n",
    "        founder.add(wikidf.iloc[idx][\"founded_byLabel\"])\n",
    "        parentOrganization.add((wikidf.iloc[idx][\"parent\"], wikidf.iloc[idx][\"parentLabel\"]))\n",
    "        subOrganization.add((wikidf.iloc[idx][\"subsidiary\"], wikidf.iloc[idx][\"subsidiaryLabel\"]))\n",
    "        CEO.add(wikidf.iloc[idx][\"CEOLabel\"])\n",
    "    \n",
    "    founder -= remove\n",
    "    parentOrganization -= remove2 \n",
    "    subOrganization -= remove2\n",
    "    CEO -= remove \n",
    "        \n",
    "    return founder, parentOrganization, subOrganization, CEO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Competitors', 'Founded', 'Headquarters', 'Rating',\n",
       "       'Revenue', 'Sector', 'Size', 'Type of ownership', 'Website',\n",
       "       'Company Description', 'wikisite', 'uri_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URI', 'URILabel', 'comURI', 'founded_by', 'founded_byLabel', 'CEO',\n",
       "       'CEOLabel', 'parent', 'parentLabel', 'subsidiary', 'subsidiaryLabel',\n",
       "       'total_revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company RDF\n",
    "for i in range(len(df)):\n",
    "    node_uri = URIRef(MYNS[df.iloc[i][\"uri_name\"]])\n",
    "    my_kg.add((node_uri, RDF.type, MYNS['company']))\n",
    "\n",
    "    my_kg.add((node_uri, schema['name'], Literal(df.iloc[i]['Company Name'])))    \n",
    "   \n",
    "    if df.iloc[i]['Competitors'] != \"missing!\":\n",
    "        my_kg.add((node_uri, MYNS['competitors'], Literal(df.iloc[i]['Competitors'])))\n",
    "    \n",
    "    if df.iloc[i]['Founded'] != \"missing!\":\n",
    "        my_kg.add((node_uri, schema['foundingYear'], Literal(int(df.iloc[i]['Founded']))))\n",
    "\n",
    "    if df.iloc[i]['Headquarters'] != \"missing!\":\n",
    "        my_kg.add((node_uri, MYNS['headquarters'], Literal(df.iloc[i]['Headquarters'])))\n",
    "\n",
    "    if df.iloc[i]['Rating'] != \"missing!\":\n",
    "        my_kg.add((node_uri, schema['aggregateRating'], Literal(df.iloc[i]['Rating'])))\n",
    "\n",
    "    if df.iloc[i]['Revenue'] != \"missing!\":\n",
    "        my_kg.add((node_uri, MYNS['revenue'], Literal(df.iloc[i]['Revenue'])))\n",
    "\n",
    "    if df.iloc[i]['Sector'] != \"missing!\":\n",
    "        my_kg.add((node_uri, MYNS['sector'], Literal(df.iloc[i]['Sector'])))\n",
    "    \n",
    "    if df.iloc[i]['Size'] != \"missing!\":        \n",
    "        my_kg.add((node_uri, schema['numberOfEmployees'], Literal(df.iloc[i]['Size'])))\n",
    "    \n",
    "    if df.iloc[i]['Type of ownership'] != \"missing!\":\n",
    "        my_kg.add((node_uri, MYNS['ownershipType'], Literal(df.iloc[i]['Type of ownership'])))\n",
    "    \n",
    "    if df.iloc[i]['Company Description'] != \"missing!\":   \n",
    "        my_kg.add((node_uri, schema['description'], Literal(df.iloc[i]['Company Description'])))\n",
    "    \n",
    "    wikisite = df.iloc[i]['wikisite']\n",
    "    if wikisite != \"missing!\":  \n",
    "        my_kg.add((node_uri, schema['sameAs'], Literal(wikisite)))\n",
    "        idxes = wikidf.index[wikidf[\"URI\"] == wikisite].tolist()\n",
    "        \n",
    "        if df.iloc[i]['Website'] != \"missing!\":\n",
    "            my_kg.add((node_uri, schema['url'], Literal(df.iloc[i]['Website'])))\n",
    "        else:\n",
    "            comURI = wikidf.iloc[idxes[0]][\"comURI\"]\n",
    "            if comURI != \"-1\":\n",
    "                my_kg.add((node_uri, schema['url'], Literal(comURI)))\n",
    "        \n",
    "        founder, parentOrganization, subOrganization, CEO = getwiki(idxes)\n",
    "        \n",
    "        for fo in founder:\n",
    "            my_kg.add((node_uri, schema['founder'], Literal(fo)))\n",
    "        \n",
    "        for ce in CEO:\n",
    "            my_kg.add((node_uri, MYNS['ceo'], Literal(ce)))\n",
    "            \n",
    "        for paURI, parent in parentOrganization:\n",
    "            parent_uri = URIRef(paURI)\n",
    "            my_kg.add((node_uri, schema['parentOrganization'], parent_uri))\n",
    "            my_kg.add((parent_uri, schema['name'], Literal(parent)))\n",
    "        \n",
    "        for subURI, sub in subOrganization:\n",
    "            sub_uri = URIRef(subURI)\n",
    "            my_kg.add((node_uri, schema['subOrganization'], sub_uri))\n",
    "            my_kg.add((sub_uri, schema['name'], Literal(sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job RDF: industry, job description, job title, location, salary est, company, skills (job description)\n",
    "jobdf = pd.read_csv(\"cleaned_jobs.csv\")\n",
    "jobdf.fillna(\"missing!\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Competitors', 'Founded', 'Headquarters', 'Industry',\n",
       "       'Job Description', 'Job Title', 'Location', 'Rating', 'Revenue',\n",
       "       'Salary Estimate', 'Sector', 'Size', 'Type of ownership', 'timestamp',\n",
       "       'SE/DS', 'Website', 'Company Description', 'wikisite', 'uri_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectCol = list(set(jobdf.columns) - set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salary Estimate',\n",
       " 'SE/DS',\n",
       " 'Location',\n",
       " 'Industry',\n",
       " 'Job Description',\n",
       " 'timestamp',\n",
       " 'Job Title']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectCol.remove('timestamp')\n",
    "selectCol.append('uri_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salary Estimate',\n",
       " 'SE/DS',\n",
       " 'Location',\n",
       " 'Industry',\n",
       " 'Job Description',\n",
       " 'Job Title',\n",
       " 'uri_name']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdf2 = jobdf[selectCol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Myunghee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "joburl = [\"job\"+str(i) for i in range(len(jobdf2))]\n",
    "jobdf2['joburl'] = joburl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Salary Estimate', 'SE/DS', 'Location', 'Industry', 'Job Description',\n",
       "       'Job Title', 'uri_name', 'joburl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobdf2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs RDF\n",
    "for i in range(len(jobdf2)):\n",
    "    node_uri = URIRef(MYNS[jobdf2.iloc[i][\"joburl\"]])\n",
    "    my_kg.add((node_uri, RDF.type, MYNS['job']))\n",
    "    \n",
    "    my_kg.add((node_uri, MYNS['job_title'], Literal(jobdf2.iloc[i]['Job Title'])))\n",
    "    description = jobdf2.iloc[i]['Job Description'] \n",
    "    if description != \"missing!\":\n",
    "        description = re.sub(r\"[\\r\\n]\", \"\", description)\n",
    "        my_kg.add((node_uri, schema['description'], Literal(description)))\n",
    "    \n",
    "    if jobdf2.iloc[i]['Salary Estimate'] != \"missing!\":\n",
    "        my_kg.add((node_uri, schema['salary_estimate'], Literal(jobdf2.iloc[i]['Salary Estimate'])))    \n",
    "    \n",
    "    my_kg.add((node_uri, MYNS['se_ds'], Literal(jobdf2.iloc[i]['SE/DS'])))    \n",
    "   \n",
    "    if jobdf2.iloc[i]['Location'] != \"missing!\":\n",
    "        my_kg.add((node_uri, schema['location'], Literal(jobdf2.iloc[i]['Location'])))\n",
    "\n",
    "    if jobdf2.iloc[i]['Industry'] != \"missing!\":\n",
    "        my_kg.add((node_uri, MYNS['industry'], Literal(jobdf2.iloc[i]['Industry'])))\n",
    "       \n",
    "    company_uri = URIRef(MYNS[jobdf2.iloc[i][\"uri_name\"]])\n",
    "    my_kg.add((node_uri, MYNS['company'], company_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.serialize('companyJobsRDF.ttl', format=\"turtle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
